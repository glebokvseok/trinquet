version: '3.9'

services:
  auth_service:
    image: cr.yandex/crp8adrosk06oijuu5pd/auth-service:latest-amd64
    hostname: auth-service
    networks:
      - default
    environment:
      APP_MODE: ${APP_MODE}
      HTTP_SERVER_PORT: ${AUTH_SERVICE_HTTP_SERVER_PORT}
      USER_ACCESS_TOKEN_SIGNING_KEY: ${USER_ACCESS_TOKEN_SIGNING_KEY}
      USER_REFRESH_TOKEN_SIGNING_KEY: ${USER_REFRESH_TOKEN_SIGNING_KEY}
      REQUEST_SIGNING_KEY: ${REQUEST_SIGNING_KEY}
      
      DATABASE_CONNECTION_STRING: ${AUTH_SERVICE_DATABASE_CONNECTION_STRING}
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          cpus: '0.1'
          memory: 512M
          pids: 10
        reservations:
          cpus: '0.05'
          memory: 256M
      placement:
        preferences:
          - spread: node.labels.host
      restart_policy:
        condition: any
        delay: 15s
      update_config:
        parallelism: 1
        monitor: 10s
        delay: 5s
        order: start-first
        failure_action: rollback
      rollback_config:
        parallelism: 1
        monitor: 10s
        delay: 5s
        order: start-first
        failure_action: rollback
    volumes:
      - /trinquet/.data/yc/root.crt:/etc/ssl/certs/yc/root.crt:ro
    healthcheck:
      test: curl -f http://localhost:${AUTH_SERVICE_HTTP_SERVER_PORT}/v0/auth-service/health-check
      start_period: 15s
      interval: 10s
      timeout: 5s
      retries: 3

  court_service:
    image: cr.yandex/crp8adrosk06oijuu5pd/court-service:latest-amd64
    hostname: court-service
    networks:
      - default
    environment:
      APP_MODE: ${APP_MODE}
      HTTP_SERVER_PORT: ${COURT_SERVICE_HTTP_SERVER_PORT}
      USER_ACCESS_TOKEN_SIGNING_KEY: ${USER_ACCESS_TOKEN_SIGNING_KEY}
      REQUEST_SIGNING_KEY: ${REQUEST_SIGNING_KEY}

      DATABASE_CONNECTION_STRING: ${COURT_SERVICE_DATABASE_CONNECTION_STRING}

      AWS_REGION: ${AWS_REGION}
      AWS_ENDPOINT_URL: ${AWS_ENDPOINT_URL}
      AWS_ACCESS_KEY_ID: ${COURT_SERVICE_AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${COURT_SERVICE_AWS_SECRET_ACCESS_KEY}
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          cpus: '0.1'
          memory: 512M
          pids: 10
        reservations:
          cpus: '0.05'
          memory: 256M
      placement:
        preferences:
          - spread: node.labels.host
      restart_policy:
        condition: any
        delay: 15s
      update_config:
        parallelism: 1
        monitor: 10s
        delay: 5s
        order: start-first
        failure_action: rollback
      rollback_config:
        parallelism: 1
        monitor: 10s
        delay: 5s
        order: start-first
        failure_action: rollback
    volumes:
      - /trinquet/.data/yc/root.crt:/etc/ssl/certs/yc/root.crt:ro
    healthcheck:
      test: curl -f http://localhost:${COURT_SERVICE_HTTP_SERVER_PORT}/v0/court-service/health-check
      start_period: 15s
      interval: 10s
      timeout: 5s
      retries: 3

  newsfeed_service:
    image: cr.yandex/crp8adrosk06oijuu5pd/newsfeed-service:latest-amd64
    hostname: newsfeed-service
    networks:
      - default
    environment:
      APP_MODE: ${APP_MODE}
      HTTP_SERVER_PORT: ${NEWSFEED_SERVICE_HTTP_SERVER_PORT}
      USER_ACCESS_TOKEN_SIGNING_KEY: ${USER_ACCESS_TOKEN_SIGNING_KEY}
      REQUEST_SIGNING_KEY: ${REQUEST_SIGNING_KEY}

      NEWSFEED_DATABASE_CONNECTION_STRING: ${NEWSFEED_DATABASE_CONNECTION_STRING}

      KAFKA_USERNAME: ${NEWSFEED_SERVICE_KAFKA_USERNAME}
      KAFKA_PASSWORD: ${NEWSFEED_SERVICE_KAFKA_PASSWORD}
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      KAFKA_SSL_ROOT_CERT: ${KAFKA_SSL_ROOT_CERT}

      AWS_REGION: ${AWS_REGION}
      AWS_ENDPOINT_URL: ${AWS_ENDPOINT_URL}
      AWS_ACCESS_KEY_ID: ${NEWSFEED_SERVICE_AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${NEWSFEED_SERVICE_AWS_SECRET_ACCESS_KEY}

      PLAYER_SERVICE_GRPC_HOST: ${PLAYER_SERVICE_GRPC_HOST}
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          cpus: '0.2'
          memory: 512M
          pids: 50
        reservations:
          cpus: '0.1'
          memory: 256M
      placement:
        preferences:
          - spread: node.labels.host
      restart_policy:
        condition: any
        delay: 15s
      update_config:
        parallelism: 1
        monitor: 10s
        delay: 5s
        order: start-first
        failure_action: rollback
      rollback_config:
        parallelism: 1
        monitor: 10s
        delay: 5s
        order: start-first
        failure_action: rollback
    volumes:
      - /trinquet/.data/yc/root.crt:/etc/ssl/certs/yc/root.crt:ro
    healthcheck:
      test: curl -f http://localhost:${NEWSFEED_SERVICE_HTTP_SERVER_PORT}/v0/newsfeed-service/health-check
      start_period: 15s
      interval: 10s
      timeout: 5s
      retries: 3

  player_service:
    image: cr.yandex/crp8adrosk06oijuu5pd/player-service:latest-amd64
    hostname: player-service
    networks:
      - default
    environment:
      APP_MODE: ${APP_MODE}
      HTTP_SERVER_PORT: ${PLAYER_SERVICE_HTTP_SERVER_PORT}
      GRPC_SERVER_PORT: ${PLAYER_SERVICE_GRPC_SERVER_PORT}
      USER_ACCESS_TOKEN_SIGNING_KEY: ${USER_ACCESS_TOKEN_SIGNING_KEY}
      REQUEST_SIGNING_KEY: ${REQUEST_SIGNING_KEY}

      PLAYER_DATABASE_CONNECTION_STRING: ${PLAYER_SERVICE_PLAYER_DATABASE_CONNECTION_STRING}

      USER_RELATION_DATABASE_URI: ${PLAYER_SERVICE_USER_RELATION_DATABASE_URI}
      USER_RELATION_DATABASE_NAME: ${PLAYER_SERVICE_USER_RELATION_DATABASE_NAME}
      USER_RELATION_DATABASE_USERNAME: ${PLAYER_SERVICE_USER_RELATION_DATABASE_USERNAME}
      USER_RELATION_DATABASE_PASSWORD: ${PLAYER_SERVICE_USER_RELATION_DATABASE_PASSWORD}
      USER_RELATION_DATABASE_SSL_ROOT_CERT: ${PLAYER_SERVICE_USER_RELATION_DATABASE_SSL_ROOT_CERT}

      AWS_REGION: ${AWS_REGION}
      AWS_ENDPOINT_URL: ${AWS_ENDPOINT_URL}
      AWS_ACCESS_KEY_ID: ${PLAYER_SERVICE_AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${PLAYER_SERVICE_AWS_SECRET_ACCESS_KEY}
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          cpus: '0.1'
          memory: 512M
          pids: 10
        reservations:
          cpus: '0.05'
          memory: 256M
      placement:
        preferences:
          - spread: node.labels.host
      restart_policy:
        condition: any
        delay: 15s
      update_config:
        parallelism: 1
        monitor: 10s
        delay: 5s
        order: start-first
        failure_action: rollback
      rollback_config:
        parallelism: 1
        monitor: 10s
        delay: 5s
        order: start-first
        failure_action: rollback
    volumes:
      - /trinquet/.data/yc/root.crt:/etc/ssl/certs/yc/root.crt:ro
      - /trinquet/.data/neo4j/certs/ca.pem:/etc/ssl/certs/neo4j/ca.pem:ro
    healthcheck:
      test: curl -f http://localhost:${PLAYER_SERVICE_HTTP_SERVER_PORT}/v0/player-service/health-check
      start_period: 15s
      interval: 10s
      timeout: 5s
      retries: 3

  chat_service:
    image: cr.yandex/crp8adrosk06oijuu5pd/chat-service:latest-amd64
    hostname: chat-service
    networks:
      - default
    environment:
      APP_MODE: ${APP_MODE}
      HTTP_SERVER_PORT: ${CHAT_SERVICE_HTTP_SERVER_PORT}
      USER_ACCESS_TOKEN_SIGNING_KEY: ${USER_ACCESS_TOKEN_SIGNING_KEY}
      REQUEST_SIGNING_KEY: ${REQUEST_SIGNING_KEY}

      NOTIFICATION_DATABASE_CONNECTION_STRING: ${CHAT_DATABASE_CONNECTION_STRING}

      KAFKA_USERNAME: ${CHAT_SERVICE_KAFKA_USERNAME}
      KAFKA_PASSWORD: ${CHAT_SERVICE_KAFKA_PASSWORD}
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      KAFKA_SSL_ROOT_CERT: ${KAFKA_SSL_ROOT_CERT}
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          cpus: '0.2'
          memory: 512M
          pids: 50
        reservations:
          cpus: '0.1'
          memory: 256M
      placement:
        preferences:
          - spread: node.labels.host
      restart_policy:
        condition: any
        delay: 15s
      update_config:
        parallelism: 1
        monitor: 10s
        delay: 5s
        order: start-first
        failure_action: rollback
      rollback_config:
        parallelism: 1
        monitor: 10s
        delay: 5s
        order: start-first
        failure_action: rollback
    volumes:
      - /trinquet/.data/yc/root.crt:/etc/ssl/certs/yc/root.crt:ro
    healthcheck:
      test: curl -f http://localhost:${CHAT_SERVICE_HTTP_SERVER_PORT}/v0/chat-service/health-check
      start_period: 15s
      interval: 10s
      timeout: 5s
      retries: 3

  notification_service:
    image: cr.yandex/crp8adrosk06oijuu5pd/notification-service:latest-amd64
    hostname: notification-service
    networks:
      - default
    environment:
      APP_MODE: ${APP_MODE}
      HTTP_SERVER_PORT: ${NOTIFICATION_SERVICE_HTTP_SERVER_PORT}
      USER_ACCESS_TOKEN_SIGNING_KEY: ${USER_ACCESS_TOKEN_SIGNING_KEY}
      REQUEST_SIGNING_KEY: ${REQUEST_SIGNING_KEY}

      NOTIFICATION_DATABASE_CONNECTION_STRING: ${NOTIFICATION_DATABASE_CONNECTION_STRING}

      KAFKA_USERNAME: ${NOTIFICATION_SERVICE_KAFKA_USERNAME}
      KAFKA_PASSWORD: ${NOTIFICATION_SERVICE_KAFKA_PASSWORD}
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      KAFKA_SSL_ROOT_CERT: ${KAFKA_SSL_ROOT_CERT}
    deploy:
      mode: replicated
      replicas: 2
      resources:
        limits:
          cpus: '0.2'
          memory: 512M
          pids: 50
        reservations:
          cpus: '0.1'
          memory: 256M
      placement:
        preferences:
          - spread: node.labels.host
      restart_policy:
        condition: any
        delay: 15s
      update_config:
        parallelism: 1
        monitor: 10s
        delay: 5s
        order: start-first
        failure_action: rollback
      rollback_config:
        parallelism: 1
        monitor: 10s
        delay: 5s
        order: start-first
        failure_action: rollback
    volumes:
      - /trinquet/.data/yc/root.crt:/etc/ssl/certs/yc/root.crt:ro
    healthcheck:
      test: curl -f http://localhost:${NOTIFICATION_SERVICE_HTTP_SERVER_PORT}/v0/notification-service/health-check
      start_period: 15s
      interval: 10s
      timeout: 5s
      retries: 3

  neo4j:
    image: neo4j:5.26-enterprise
    hostname: neo4j
    networks:
      - default
    ports:
      - "7473:7473"
      - "7687:7687"
    environment:
      NEO4J_ACCEPT_LICENSE_AGREEMENT: "yes"
      NEO4J_AUTH: neo4j/${NEO4J_PASSWORD}
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          cpus: '1'
          memory: 2G
          pids: 250
        reservations:
          cpus: '0.5'
          memory: 1G
      placement:
        constraints:
          - node.labels.host == alpha
      restart_policy:
        condition: any
        delay: 15s
    volumes:
      - /trinquet/conf/neo4j/prod.conf:/conf/neo4j.conf:ro
      - /trinquet/.data/neo4j/certs:/ssl/:ro
      - /trinquet/.data/neo4j/data:/data
      - /trinquet/.data/neo4j/logs:/logs
    healthcheck:
      test: exit 0
      
  nginx:
    image: nginx:1.27-alpine
    networks:
      - default
    ports:
      - "80:80"
      - "443:443"
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          cpus: '0.15'
          memory: 512M
          pids: 10
        reservations:
          cpus: '0.1'
          memory: 256M
      placement:
        constraints:
          - node.labels.host == alpha
      restart_policy:
        condition: any
        delay: 15s
    volumes:
      - /trinquet/conf/nginx/prod.conf:/etc/nginx/conf.d/default.conf:ro
      - /trinquet/conf/nginx/lib:/etc/nginx/conf.d/lib/:ro
      - /trinquet/.data/certbot/conf:/etc/letsencrypt/:ro
      - /trinquet/.data/certbot/webroot:/var/www/certbot/:ro
    healthcheck:
      test: exit 0

  certbot:
    image: certbot/certbot:latest
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          cpus: '0.05'
          memory: 128M
          pids: 5
        reservations:
          cpus: '0.025'
          memory: 64M
      placement:
        constraints:
          - node.labels.host == alpha
      restart_policy:
        condition: on-failure
        delay: 5m
    volumes:
      - /trinquet/.data/certbot/conf:/etc/letsencrypt/:rw
      - /trinquet/.data/certbot/webroot:/var/www/certbot/:rw
    entrypoint: "/bin/sh -c 'trap exit TERM; while :; do certbot renew; sleep 24h & wait $${!}; done'"
    healthcheck:
      test: exit 0

networks:
  default:
    driver: overlay
